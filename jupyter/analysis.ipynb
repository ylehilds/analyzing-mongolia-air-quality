{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Done loading data...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Add the path to system, local or mounted S3 bucket, e.g. /dbfs/mnt/<path_to_bucket>\n",
    "sys.path.append('./secrets.py')\n",
    "\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "\n",
    "from influxdb import DataFrameClient\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "# Need to ssh tunnel for this to work\n",
    "# ssh -L nothing:nothing:nothing aq.byu.edu -N\n",
    "influx = DataFrameClient(\n",
    "    host=HOST,\n",
    "    port=PORT,\n",
    "    username=USERNAME,\n",
    "    password=PASSWORD,\n",
    "    database=DATABASE,\n",
    ")\n",
    "\n",
    "\n",
    "def large_query(influx, measurement, query, total=None, limit=100_000):\n",
    "    if total is not None:\n",
    "        total = math.ceil(total / limit)\n",
    "\n",
    "    with tqdm(total=total) as pbar:\n",
    "        offset = 0\n",
    "        while True:\n",
    "            new_query = query + \" LIMIT {} OFFSET {}\".format(limit, offset)\n",
    "            data = influx.query(new_query)\n",
    "            data = data[measurement]\n",
    "\n",
    "            received = len(data)\n",
    "            pbar.update(1)\n",
    "\n",
    "            yield data\n",
    "\n",
    "            offset += limit\n",
    "            if received != limit:\n",
    "                break\n",
    "\n",
    "\n",
    "def load_data(filename):\n",
    "    if os.path.exists(filename):\n",
    "        LOGGER.info(\"Loading cached data...\")\n",
    "        return pd.read_hdf(filename)\n",
    "\n",
    "    LOGGER.info(\"Downloading data...\")\n",
    "    result = influx.query(\n",
    "        \"SELECT COUNT(sequence) FROM air_quality_sensor WHERE time > '2019-10-01' AND time <= now()\"\n",
    "    )\n",
    "    count = result[\"air_quality_sensor\"].values[0][0]\n",
    "\n",
    "    queries = large_query(\n",
    "        influx,\n",
    "        \"air_quality_sensor\",\n",
    "        \"SELECT * FROM air_quality_sensor WHERE time > '2019-10-01' AND time <= now()\",\n",
    "        count,\n",
    "    )\n",
    "\n",
    "    all_data = pd.concat(list(queries), sort=False)\n",
    "    all_data.to_hdf(filename, \"data\")\n",
    "    return all_data\n",
    "\n",
    "\n",
    "data = load_data(\"aq_data.h5\")\n",
    "LOGGER.info(\"Done loading data...\")\n",
    "\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
